# -*- coding: utf-8 -*-
"""AML_ASSIGNMENT__2_villyal vidushi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GUXeoL1ZH2YlVoPhAzu9SJbG5h7eLR1b

This research seeks to explore various methods for improving the performance of a neural network model utilizing the IMDb dataset.

We will implement modifications to an existing model, examining the results of several strategies including:

**Architectural Adjustments**
   
*   Modifying Hidden Layers: Altering the number of hidden layers
*   Adjusting Layer Units: Varying the number of units within each layer.

**Functional Changes**

 * Loss Function Modification: Changing the loss function used in training.
 * Activation Function Variation: Switching different activation functions.

**Regularization Methods**

 * Dropout Techniques Implementation the regularization approach includes dropout methods that address issues of overfitting as well as tasks related to generalization.

The dataset from IMDb employed in this research comprises 50,000 film reviews, with an equal distribution of positive and negative sentiments. Of these reviews, 25,000 are designated for training the model, while the other 25,000 serve to assess its performance.

Through systematic application and evaluation of different modifications, we can gain insights into which neural network setup achieves optimal accuracy in sentiment analysis. This methodology allows us to pinpoint particular adjustments within the model that significantly improve the classification of movie reviews as either positive or negative.
"""

from numpy.random import seed
seed(123)
from tensorflow.keras.datasets import imdb
(train_reviews, train_labels), (test_reviews, test_labels) = imdb.load_data(
    num_words=10000)

train_reviews

train_labels[0]

len(train_labels)

test_reviews

test_labels[0]

max([max(sequence) for sequence in test_reviews])

""" ## **Reviews into text form**"""

word_to_id = imdb.get_word_index()
index_to_word = dict(
    [(value, key) for (key, value) in word_to_id.items()])
translated_review = " ".join(
    [index_to_word.get(i - 3, "?") for i in train_reviews[0]])

translated_review

"""## **Preparing the Data**"""

import numpy as np
def vectorize_sequences(sequences, dimension=10000):
    Outcomes = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        for j in sequence:
            Outcomes[i, j] = 1.
    return Outcomes

"""## **Data Vectorization**"""

train_review_vectors = vectorize_sequences(train_reviews)
test_review_vectors = vectorize_sequences(test_reviews)

train_review_vectors[0]

test_review_vectors[0]

"""## **Label Vectorization**"""

train_sentiment_vectors  = np.asarray(train_labels).astype("float32")
testing_sentiment_vectors= np.asarray(test_labels).astype("float32")

"""## **Building the model using relu and then compiling it**"""

from tensorflow import keras
from tensorflow.keras import layers
seed(123)
model = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

seed(123)
x_validation = train_review_vectors[:10000]
partial_train_review_vectors= train_review_vectors[10000:]
y_validation = train_sentiment_vectors[:10000]
partial_train_sentiment_vectors = train_sentiment_vectors[10000:]

seed(123)
history = model.fit(partial_train_review_vectors,
                    partial_train_sentiment_vectors,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

"""The outset of the training phase, the model recorded a loss value of 0.6044 and an accuracy of 70.44%. When evaluated on the validation dataset, it achieved an accuracy of 86.23% along with a loss of 0.4064. As the training progressed through multiple iterations, the model's performance on the training data improved significantly, ultimately reaching an almost perfect accuracy of 99.95% and a minimal loss of 0.0112 by the twentieth epoch. Conversely, the validation accuracy stabilized at approximately 86.85%, while the validation loss increased to 0.5720, clearly indicating signs of overfitting. This result suggests that the model has become too specialized in memorizing the training data, thus diminishing its performance on new, unseen data. To mitigate overfitting and improve the model's ability to generalize, strategies such as dropout, early stopping, or other regularization methods could be implemented."""

history__data = history.history
history__data.keys()

"""#**Plotting the training and validation loss**"""

import matplotlib.pyplot as plt
history_dict = history.history
loss_values = history_dict["loss"]
val_loss_values = history_dict["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, val_loss_values, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
acc = history_dict["accuracy"]
val_acc = history_dict["val_accuracy"]
plt.plot(epochs, acc, "bo", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""The graphs demonstrate signs of overfitting, evidenced by a persistent decline in training loss alongside an increase in validation loss after several epochs. Although the model reaches nearly 100% accuracy on the training set, the varying validation accuracy indicates inadequate generalization. This situation highlights the need for strategies such as regularization or early stopping to enhance overall performance.

##**Retraining the model**
"""

np.random.seed(123)
model = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
model.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
model.fit(train_review_vectors, train_sentiment_vectors, epochs=4, batch_size=512)
Outcomes = model.evaluate(test_review_vectors, testing_sentiment_vectors)

Outcomes

"""During the evaluation of the neural network model, it achieved an accuracy rate of 88.32% alongside a loss value of 0.2942. Although there are ongoing indications of overfitting based on its training outcomes, the model effectively generalizes to new data points."""

model.predict(test_review_vectors)

"""##**Building a neural network with one hidden layer**

"""

seed(123)
model1 = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model1.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

x_validation = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]


history_1 = model1.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

history_dict = history_1.history
history_dict.keys()

import matplotlib.pyplot as plt
history_dict = history_1.history
loss_values = history_dict["loss"]
validation_loss = history_dict["val_loss"]
epochs = range(1, len(loss_values) + 1)
#Plotting graph between Training and Validation loss
plt.plot(epochs, loss_values, "ro", label="Training loss")
plt.plot(epochs, validation_loss, "r", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

#Plotting graph between Training and Validation Accuracy
plt.clf()
acc = history_dict["accuracy"]
val_acc = history_dict["val_accuracy"]
plt.plot(epochs, acc, "ro", label="Training accuracy")
plt.plot(epochs, val_acc, "r", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

np.random.seed(123)
model1 = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model1.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
model1.fit(train_review_vectors, train_sentiment_vectors, epochs=5, batch_size=512)
Outcomes1 = model1.evaluate(test_review_vectors, testing_sentiment_vectors)

Outcomes1

"""The test set has a loss of 0.280 and an accuracy of 88.70%."""

model1.predict(test_review_vectors)

"""##**Creating a neural network with three hidden layers**"""

np.random.seed(123)
model_3 = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
model_3.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
x_validation = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]

history3 = model_3.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

history_dict3 = history3.history
history_dict3.keys()

loss_values = history_dict3["loss"]
validation_loss = history_dict3["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "go", label="Training loss")
plt.plot(epochs, validation_loss, "g", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict3["accuracy"]
validation_accuracy = history_dict3["val_accuracy"]
plt.plot(epochs, accuracy, "go", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "g", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

np.random.seed(123)
model_3 = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])


model_3.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model_3.fit(train_review_vectors, train_sentiment_vectors, epochs=3, batch_size=512)
Outcomes_3 = model_3.evaluate(test_review_vectors, testing_sentiment_vectors)

"""The test set has a loss of 0.3013 and an accuracy of 87.89%"""

Outcomes_3

model_3.predict(test_review_vectors)

"""The model achieved a test loss of 0.3039 and an accuracy of 87.91%, indicating strong performance in sentiment classification. However, further optimization, such as fine-tuning hyperparameters or applying regularization, may enhance generalization.

##**Building Neural Network with 32 units**
"""

np.random.seed(123)
model_32 = keras.Sequential([
    layers.Dense(32, activation="relu"),
    layers.Dense(32, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
#model compilation
model_32.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
#model validation
x_validation = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]

np.random.seed(123)
history32 = model_32.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

history_dict32 = history32.history
history_dict32.keys()

loss_values = history_dict32["loss"]
validation_loss = history_dict32["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict32["accuracy"]
validation_accuracy = history_dict32["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

history_32 = model_32.fit(train_review_vectors, train_sentiment_vectors, epochs=3, batch_size=512)
Outcomes_32 = model_32.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_32

model_32.predict(test_review_vectors)

"""##**Training the model with 64 units**"""

np.random.seed(123)
model_64 = keras.Sequential([
    layers.Dense(64, activation="relu"),
    layers.Dense(64, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
model_64.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
# validation
x_validation = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]

np.random.seed(123)
history64 = model_64.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

history_dict64 = history64.history
history_dict64.keys()

loss_values = history_dict64["loss"]
validation_loss = history_dict64["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict64["accuracy"]
validation_accuracy = history_dict64["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

history_64 = model_64.fit(train_review_vectors,
train_sentiment_vectors
, epochs=3, batch_size=512)
Outcomes_64 = model_64.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_64

model_64.predict(test_review_vectors)

"""The validation set has an accuracy of 87.07%.

##**Training the model with 128 units**
"""

np.random.seed(123)
model_128 = keras.Sequential([
    layers.Dense(128, activation="relu"),
    layers.Dense(128, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
model_128.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
# validation
x_validation = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]

np.random.seed(123)
history_128 = model_128.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

history_dict128 = history_128.history
history_dict128.keys()

loss_values = history_dict128["loss"]
validation_loss = history_dict128["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict128["accuracy"]
validation_accuracy = history_dict128["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

history_128 = model_128.fit(train_review_vectors, train_sentiment_vectors, epochs=2, batch_size=512)
Outcomes_128 = model_128.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_128

model_128.predict(test_review_vectors)

"""The validation set has an accuracy of 87.10%

##**MSE Loss Function**
"""

np.random.seed(123)
model_MSE = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
#Model compilation
model_MSE.compile(optimizer="rmsprop",
              loss="mse",
              metrics=["accuracy"])
# validation
x_validation = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]
# Model Fit
np.random.seed(123)
history_model_MSE = model_MSE.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

history_dict_MSE = history_model_MSE.history
history_dict_MSE.keys()

import matplotlib.pyplot as plt
loss_values = history_dict_MSE["loss"]
validation_loss = history_dict_MSE["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict_MSE["accuracy"]
validation_accuracy = history_dict_MSE["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

model_MSE.fit(train_review_vectors, train_sentiment_vectors, epochs=8, batch_size=512)
Outcomes_MSE = model_MSE.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_MSE

model_MSE.predict(test_review_vectors)

"""##**Tanh Activation Function**"""

np.random.seed(123)
model_tanh = keras.Sequential([
    layers.Dense(16, activation="tanh"),
    layers.Dense(16, activation="tanh"),
    layers.Dense(1, activation="sigmoid")
])

model_tanh.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

x_val = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]

np.random.seed(123)

history_tanh = model_tanh.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_val, y_validation))

history_dict_tanh = history_tanh.history
history_dict_tanh.keys()

loss_values = history_dict_tanh["loss"]
validation_loss = history_dict_tanh["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict_tanh["accuracy"]
validation_accuracy = history_dict_tanh["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

model_tanh.fit(train_review_vectors,
train_sentiment_vectors
, epochs=8, batch_size=512)
Outcomes_tanh = model_tanh.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_tanh

"""##**Adam Optimizer Function**"""

np.random.seed(123)
model_adam = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model_adam.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

x_validation = train_review_vectors[:10000]
train_reviews_subset = train_review_vectors[10000:]

y_validation = train_sentiment_vectors[:10000]
partial_y_train = train_sentiment_vectors[10000:]

np.random.seed(123)

history_adam = model_adam.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))

history_dict_adam = history_adam.history
history_dict_adam.keys()

loss_values = history_dict_adam["loss"]
validation_loss = history_dict_adam["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict_adam["accuracy"]
validation_accuracy = history_dict_adam["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

model_adam.fit(train_review_vectors, train_sentiment_vectors, epochs=4, batch_size=512)
Outcomes_adam = model_adam.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_adam

"""##**Regularization**"""

from tensorflow.keras import regularizers
np.random.seed(123)
model_regularization = keras.Sequential([
    layers.Dense(16, activation="relu",kernel_regularizer=regularizers.l2(0.001)),
    layers.Dense(16, activation="relu",kernel_regularizer=regularizers.l2(0.001)),
    layers.Dense(1, activation="sigmoid")
])
model_regularization.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
np.random.seed(123)
history_model_regularization = model_regularization.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))
history_dict_regularization = history_model_regularization.history
history_dict_regularization.keys()

loss_values = history_dict_regularization["loss"]
validation_loss = history_dict_regularization["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict_regularization["accuracy"]
validation_accuracy = history_dict_regularization["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

model_regularization.fit(train_review_vectors,
train_sentiment_vectors
, epochs=8, batch_size=512)
Outcomes_regularization = model_regularization.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_regularization

"""The loss on test set is 0.4194 and accuracy is 87.00%

## **Dropout**
"""

from tensorflow.keras import regularizers
np.random.seed(123)
model_Dropout = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dropout(0.5),
    layers.Dense(16, activation="relu"),
    layers.Dropout(0.5),
    layers.Dense(1, activation="sigmoid")
])
model_Dropout.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
np.random.seed(123)
history_model_Dropout = model_Dropout.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))
history_dict_Dropout = history_model_Dropout.history
history_dict_Dropout.keys()

loss_values = history_dict_Dropout["loss"]
validation_loss = history_dict_Dropout["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict_Dropout["accuracy"]
validation_accuracy = history_dict_Dropout["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

model_Dropout.fit(train_review_vectors, train_sentiment_vectors, epochs=8, batch_size=512)
Outcomes_Dropout = model_Dropout.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_Dropout

"""loss on the test set is 0.455 and accuracy is 0.8736

#**Training moel with hyper tuned parameters**
"""

from tensorflow.keras import regularizers
np.random.seed(123)
model_Hyper = keras.Sequential([
    layers.Dense(32, activation="relu",kernel_regularizer=regularizers.l2(0.0001)),
    layers.Dropout(0.5),
    layers.Dense(32, activation="relu",kernel_regularizer=regularizers.l2(0.0001)),
    layers.Dropout(0.5),
    layers.Dense(16, activation="relu",kernel_regularizer=regularizers.l2(0.0001)),
    layers.Dropout(0.5),
    layers.Dense(1, activation="sigmoid")
])
model_Hyper.compile(optimizer="rmsprop",
              loss="mse",
              metrics=["accuracy"])
np.random.seed(123)
history_model_Hyper = model_Hyper.fit(train_reviews_subset,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_validation, y_validation))
history_dict_Hyper = history_model_Hyper.history
history_dict_Hyper.keys()

loss_values = history_dict_Hyper["loss"]
validation_loss = history_dict_Hyper["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, validation_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf()
accuracy = history_dict_Hyper["accuracy"]
validation_accuracy = history_dict_Hyper["val_accuracy"]
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, validation_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

model_Hyper.fit(train_review_vectors, train_sentiment_vectors, epochs=8, batch_size=512)
Outcomes_Hyper = model_Hyper.evaluate(test_review_vectors, testing_sentiment_vectors)
Outcomes_Hyper

"""#**Summary**"""

All_Models_Loss= np.array([Outcomes_Dropout[0],Outcomes_Hyper[0],Outcomes_MSE[0],Outcomes_regularization[0],Outcomes_tanh[0]])*100
All_Models_Loss
All_Models_Accuracy= np.array([Outcomes_Dropout[1],Outcomes_Hyper[1],Outcomes_MSE[1],Outcomes_regularization[1],Outcomes_tanh[1]])*100
All_Models_Accuracy
Labels=['Model_Dropout','Model_Hyper','Model_MSE','model_regularization','model_tanh']
plt.clf()

"""##**Compilation**"""

fig, ax = plt.subplots()
ax.scatter(All_Models_Loss,All_Models_Accuracy)
for i, txt in enumerate(Labels):
    ax.annotate(txt, (All_Models_Loss[i],All_Models_Accuracy[i] ))
plt.title("Summary for Accuracy and Loss of the Model")
plt.ylabel("Accuracy")
plt.xlabel("Loss")

plt.show()

"""### **Model Performance Summary and Comparison**

This research investigated various neural network architectures and optimization techniques aimed at enhancing the accuracy of sentiment analysis while mitigating overfitting. Significant experiments included hyperparameter tuning, dropout regularization, the implementation of the MSE loss function, and the evaluation of different activation functions.

**Model_Hyper** achieved superior results with an accuracy nearing 88% and minimal loss, highlighting the effectiveness of precise hyperparameter tuning.
**Model_MSE** showed competitive performance at 86.5% accuracy, confirming the suitability of MSE for classification tasks.
**Model_Dropout** recorded approximately 87% accuracy, illustrating the beneficial impact of dropout on generalization.

Although regularization techniques such as dropout and L2 weight decay enhanced generalization, they did lead to a slight decrease in accuracy. The choice of activation functions was crucial; ReLU consistently outperformed tanh, as evidenced by **Model_Tanh**, which exhibited the lowest accuracy (~85%).

### **Key Insights**

- Hyperparameter tuning strikes an optimal balance between accuracy and loss.
- Regularization methods can reduce overfitting but may have a minor adverse effect on performance.
- ReLU activation facilitates quicker and more effective learning compared to tanh.
- Excessive use of regularization might inadvertently result in overfitting.

### **Conclusion**

The model that performed best integrated hyperparameter tuning with MSE loss, achieving both robust generalization and high accuracy. While deeper networks provided a slight enhancement in accuracy, they also heightened the risk of overfitting. Simpler models featuring one or two hidden layers delivered comparable outcomes with greater stability. Future enhancements could involve experimenting with new activation functions, adaptive regularization strategies, and optimized dropout rates to further enhance model reliability.
"""







